{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11a2567a-3686-48ae-86eb-933688912dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import mindspore\n",
    "import   mindspore.dataset  as   ds\n",
    "import mindspore.dataset.vision.c_transforms  as  transforms\n",
    "class_labels={'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '10': 10, '11': 11, '12': 12, '13': 13, '14': 14, '15': 15, '16': 16, '17': 17, '18': 18, '19': 19, '20': 20, '21': 21, '22': 22, '23': 23, '24': 24, '25': 25, '26': 26, '27': 27, '28': 28, '29': 29, '30': 30, '31': 31, '32': 32, '33': 33, '34': 34, '35': 35, '36': 36, '37': 37, '38': 38, '39': 39, '40': 40, '41': 41, '42': 42, '43': 43, '44': 44, '45': 45, '46': 46, '47': 47, '48': 48, '49': 49, '50': 50, '51': 51, '52': 52, '53': 53}\n",
    "\n",
    "#{'工艺品/仿唐三彩': 0, '工艺品/仿宋木叶盏': 1, '工艺品/布贴绣': 2, '工艺品/景泰蓝': 3, '工艺品/木马勺脸谱': 4, '工艺品/柳编': 5, '工艺品/葡萄花鸟纹银香囊': 6, '工艺品/西安剪纸': 7, '工艺品/陕历博唐妞系列': 8, '景点/关中书院': 9, '景点/兵马俑': 10, '景点/南五台': 11, '景点/大兴善寺': 12, '景点/大观楼': 13, '景点/大雁塔': 14, '景点/小雁塔': 15, '景点/未央宫城墙遗址': 16, '景点/水陆庵壁塑': 17, '景点/汉长安城遗址': 18, '景点/西安城墙': 19, '景点/钟楼': 20, '景点/长安华严寺': 21, '景点/阿房宫遗址': 22, '民俗/唢呐': 23, '民俗/皮影': 24, '特产/临潼火晶柿子': 25, '特产/山茱萸': 26, '特产/玉器': 27, '特产/阎良甜瓜': 28, '特产/陕北红小豆': 29, '特产/高陵冬枣': 30, '美食/八宝玫瑰镜糕': 31, '美食/凉皮': 32, '美食/凉鱼': 33, '美食/德懋恭水晶饼': 34, '美食/搅团': 35, '美食/枸杞炖银耳': 36, '美食/柿子饼': 37, '美食/浆水面': 38, '美食/灌汤包': 39, '美食/烧肘子': 40, '美食/石子饼': 41, '美食/神仙粉': 42, '美食/粉汤羊血': 43, '美食/羊肉泡馍': 44, '美食/肉夹馍': 45, '美食/荞面饸饹': 46, '美食/菠菜面': 47, '美食/蜂蜜凉粽子': 48, '美食/蜜饯张口酥饺': 49, '美食/西安油茶': 50, '美食/贵妃鸡翅': 51, '美食/醪糟': 52, '美食/金线油塔': 53}\n",
    "image_size=380\n",
    "mindspore.set_seed(666777)\n",
    "\n",
    "mindspore.context.set_context(device_target=\"Ascend\")\n",
    "\n",
    "def create_dataset(path, batch_size=64, train=True, image_size=image_size):\n",
    "    dataset = ds.ImageFolderDataset(path, num_parallel_workers=8, class_indexing=class_labels)\n",
    "\n",
    "    # 图像增强操作\n",
    "    mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "    std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "    if train:\n",
    "        trans = [\n",
    "            transforms.RandomCropDecodeResize(image_size, scale=(0.08, 1.0), ratio=(0.75, 1.333)),\n",
    "            #transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.RandomHorizontalFlip(prob=0.5),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "            transforms.HWC2CHW()\n",
    "        ]\n",
    "    else:\n",
    "        trans = [\n",
    "            transforms.Decode(),\n",
    "            transforms.Resize([image_size,image_size]),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "            transforms.HWC2CHW()\n",
    "        ]\n",
    "\n",
    "    dataset = dataset.map(operations=trans, input_columns=\"image\", num_parallel_workers=8)\n",
    "    # 设置batch_size的大小，若最后一次抓取的样本数小于batch_size，则丢弃\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9382ada2-9006-4723-9bc2-dbdb666ad414",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载训练数据集\n",
    "train_path = \"/data/mindcon/dataset2/train\"\n",
    "dataset_train = create_dataset(train_path, train=True)\n",
    "\n",
    "# 加载验证数据集\n",
    "val_path = \"/data/mindcon/dataset2/val\"\n",
    "dataset_val = create_dataset(val_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cb67ba-93db-433c-9f83-9e1e5f6e3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Tensor\n",
    "from typing import Any, Type, Union, List,Optional\n",
    "from mindspore import nn\n",
    "from mindspore.ops import operations as P\n",
    "class ConvNormActivation(nn.Cell):\n",
    "    \"\"\"\n",
    "    Convolution/Depthwise fused with normalization and activation blocks definition.\n",
    "\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        out_planes (int): Output channel.\n",
    "        kernel_size (int): Input kernel size.\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 1.\n",
    "        groups (int): channel group. Convolution is 1 while Depthiwse is input channel. Default: 1.\n",
    "        norm (nn.Cell, optional): Norm layer that will be stacked on top of the convolution\n",
    "        layer. Default: nn.BatchNorm2d.\n",
    "        activation (nn.Cell, optional): Activation function which will be stacked on top of the\n",
    "        normalization layer (if not None), otherwise on top of the conv layer. Default: nn.ReLU.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> conv = ConvNormActivation(16, 256, kernel_size=1, stride=1, groups=1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_planes: int,\n",
    "                 out_planes: int,\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 groups: int = 1,\n",
    "                 norm: Optional[nn.Cell] = nn.BatchNorm2d,\n",
    "                 activation: Optional[nn.Cell] = nn.ReLU\n",
    "                 ) -> None:\n",
    "        super(ConvNormActivation, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                in_planes,\n",
    "                out_planes,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                pad_mode='pad',\n",
    "                padding=padding,\n",
    "                group=groups\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if norm:\n",
    "            layers.append(norm(out_planes))\n",
    "        if activation:\n",
    "            layers.append(activation())\n",
    "\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n",
    "\n",
    "class GlobalAvgPooling(nn.Cell):\n",
    "    \"\"\"\n",
    "    Global avg pooling definition.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> GlobalAvgPooling()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 keep_dims: bool = False\n",
    "                 ) -> None:\n",
    "        super(GlobalAvgPooling, self).__init__()\n",
    "        self.mean = P.ReduceMean(keep_dims=keep_dims)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.mean(x, (2, 3))\n",
    "        return x\n",
    "    \n",
    "class DenseHead(nn.Cell):\n",
    "    \"\"\"\n",
    "    LinearClsHead architecture.\n",
    "\n",
    "    Args:\n",
    "        input_channel (int): The number of input channel.\n",
    "        num_classes (int): Number of classes.\n",
    "        has_bias (bool): Specifies whether the layer uses a bias vector. Default: True.\n",
    "        activation (Union[str, Cell, Primitive]): activate function applied to the output. Eg. `ReLU`. Default: None.\n",
    "        keep_prob (float): Dropout keeping rate, between [0, 1]. E.g. rate=0.9, means dropping out 10% of input.\n",
    "            Default: 1.0.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_channel: int,\n",
    "                 num_classes: int,\n",
    "                 has_bias: bool = True,\n",
    "                 activation: Optional[Union[str, nn.Cell]] = None,\n",
    "                 keep_prob: float = 1.0\n",
    "                 ) -> None:\n",
    "        super(DenseHead, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(keep_prob)\n",
    "        self.dense = nn.Dense(input_channel, num_classes, has_bias=has_bias, activation=activation)\n",
    "\n",
    "    def construct(self, x):\n",
    "        if self.training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "class BaseClassifier(nn.Cell):\n",
    "    \"\"\"\n",
    "    generate classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone, neck=None, head=None):\n",
    "        super(BaseClassifier, self).__init__()\n",
    "        self.backbone = build_backbone(backbone) if isinstance(backbone, dict) else backbone\n",
    "        if neck:\n",
    "            self.neck = build_neck(neck) if isinstance(neck, dict) else neck\n",
    "            self.with_neck = True\n",
    "        else:\n",
    "            self.with_neck = False\n",
    "        if head:\n",
    "            self.head = build_head(head) if isinstance(head, dict) else head\n",
    "            self.with_head = True\n",
    "        else:\n",
    "            self.with_head = False\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.backbone(x)\n",
    "        if self.with_neck:\n",
    "            x = self.neck(x)\n",
    "        if self.with_head:\n",
    "            x = self.head(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class ResidualBlockBase(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet residual block base definition.\n",
    "\n",
    "    Args:\n",
    "        in_channel (int): Input channel.\n",
    "        out_channel (int): Output channel.\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 1.\n",
    "        group (int): Group convolutions. Default: 1.\n",
    "        base_with (int): Width of per group. Default: 64.\n",
    "        norm (nn.Cell, optional): Module specifying the normalization layer to use. Default: None.\n",
    "        down_sample (nn.Cell, optional): Downsample structure. Default: None.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> ResidualBlockBase(3, 256, stride=2)\n",
    "    \"\"\"\n",
    "\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channel: int,\n",
    "                 out_channel: int,\n",
    "                 stride: int = 1,\n",
    "                 group: int = 1,\n",
    "                 base_width: int = 64,\n",
    "                 norm: Optional[nn.Cell] = None,\n",
    "                 down_sample: Optional[nn.Cell] = None\n",
    "                 ) -> None:\n",
    "        super(ResidualBlockBase, self).__init__()\n",
    "        if not norm:\n",
    "            norm = nn.BatchNorm2d\n",
    "        assert group != 1 or base_width == 64, \"ResidualBlockBase only supports groups=1 and base_width=64\"\n",
    "        self.conv1 = ConvNormActivation(\n",
    "            in_channel,\n",
    "            out_channel,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            norm=norm)\n",
    "        self.conv2 = ConvNormActivation(\n",
    "            out_channel,\n",
    "            out_channel,\n",
    "            kernel_size=3,\n",
    "            norm=norm,\n",
    "            activation=None)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"ResidualBlockBase construct.\"\"\"\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.down_sample:\n",
    "            identity = self.down_sample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet residual block definition.\n",
    "\n",
    "    Args:\n",
    "        in_channel (int): Input channel.\n",
    "        out_channel (int): Output channel.\n",
    "        stride (int): Stride size for the second convolutional layer. Default: 1.\n",
    "        group (int): Group convolutions. Default: 1.\n",
    "        base_with (int): Width of per group. Default: 64.\n",
    "        norm (nn.Cell, optional): Module specifying the normalization layer to use. Default: None.\n",
    "        down_sample (nn.Cell, optional): Downsample structure. Default: None.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> ResidualBlock(3, 256, stride=2)\n",
    "    \"\"\"\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channel: int,\n",
    "                 out_channel: int,\n",
    "                 stride: int = 1,\n",
    "                 group: int = 1,\n",
    "                 base_width: int = 64,\n",
    "                 norm: Optional[nn.Cell] = None,\n",
    "                 down_sample: Optional[nn.Cell] = None\n",
    "                 ) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if not norm:\n",
    "            norm = nn.BatchNorm2d\n",
    "        out_channel = int(out_channel * (base_width / 64.0)) * group\n",
    "\n",
    "        self.conv1 = ConvNormActivation(\n",
    "            in_channel, out_channel, kernel_size=1, norm=norm)\n",
    "        self.conv2 = ConvNormActivation(\n",
    "            out_channel,\n",
    "            out_channel,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            groups=group,\n",
    "            norm=norm)\n",
    "        self.conv3 = ConvNormActivation(\n",
    "            out_channel,\n",
    "            out_channel *\n",
    "            self.expansion,\n",
    "            kernel_size=1,\n",
    "            norm=norm,\n",
    "            activation=None)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.down_sample = down_sample\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"ResidualBlock construct.\"\"\"\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        if self.down_sample:\n",
    "            identity = self.down_sample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet architecture.\n",
    "\n",
    "    Args:\n",
    "        block (Type[Union[ResidualBlockBase, ResidualBlock]]): Block for network.\n",
    "        layer_nums (List[int]): Numbers of block in different layers.\n",
    "        group (int): Group convolutions. Default: 1.\n",
    "        base_width (int): Width of per group. Default: 64.\n",
    "        norm (nn.Cell, optional): Module specifying the normalization layer to use. Default: None.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> ResNet(ResidualBlock, [3, 4, 6, 3])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "                 layer_nums: List[int],\n",
    "                 group: int = 1,\n",
    "                 base_with: int = 64,\n",
    "                 norm: Optional[nn.Cell] = None\n",
    "                 ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if not norm:\n",
    "            norm = nn.BatchNorm2d\n",
    "        self.norm = norm\n",
    "        self.in_channels = 64\n",
    "        self.group = group\n",
    "        self.base_with = base_with\n",
    "        self.conv1 = ConvNormActivation(\n",
    "            3, self.in_channels, kernel_size=7, stride=2, norm=norm)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='same')\n",
    "        self.layer1 = self._make_layer(block, 64, layer_nums[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layer_nums[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layer_nums[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layer_nums[3], stride=2)\n",
    "\n",
    "    def _make_layer(self,\n",
    "                    block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "                    channel: int,\n",
    "                    block_nums: int,\n",
    "                    stride: int = 1\n",
    "                    ):\n",
    "        \"\"\"Block layers.\"\"\"\n",
    "        down_sample = None\n",
    "\n",
    "        if stride != 1 or self.in_channels != self.in_channels * block.expansion:\n",
    "            down_sample = ConvNormActivation(\n",
    "                self.in_channels,\n",
    "                channel * block.expansion,\n",
    "                kernel_size=1,\n",
    "                stride=stride,\n",
    "                norm=self.norm,\n",
    "                activation=None)\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channels,\n",
    "                channel,\n",
    "                stride=stride,\n",
    "                down_sample=down_sample,\n",
    "                group=self.group,\n",
    "                base_width=self.base_with,\n",
    "                norm=self.norm\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = channel * block.expansion\n",
    "\n",
    "        for _ in range(1, block_nums):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.in_channels,\n",
    "                    channel,\n",
    "                    group=self.group,\n",
    "                    base_width=self.base_with,\n",
    "                    norm=self.norm\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet(arch: str,\n",
    "            block: Type[Union[ResidualBlockBase, ResidualBlock]],\n",
    "            layers: List[int],\n",
    "            num_classes: int,\n",
    "            pretrained: bool,\n",
    "            input_channel: int,\n",
    "            **kwargs: Any\n",
    "            ) -> ResNet:\n",
    "    \"\"\"ResNet architecture.\"\"\"\n",
    "    backbone = ResNet(block, layers, **kwargs)\n",
    "    neck = GlobalAvgPooling()\n",
    "    head = DenseHead(input_channel=input_channel, num_classes=num_classes)\n",
    "    model = BaseClassifier(backbone, neck, head)\n",
    "\n",
    "    if pretrained:\n",
    "        # Download the pre-trained checkpoint file from url, and load\n",
    "        # checkpoint file.\n",
    "        LoadPretrainedModel(model, model_urls[arch]).run()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resnet18(\n",
    "        num_classes: int = 1000,\n",
    "        pretrained: bool = False,\n",
    "        **kwargs: Any) -> ResNet:\n",
    "    \"\"\"\n",
    "    ResNet18 architecture.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of classification. Default: 1000.\n",
    "        pretrained (bool): Download and load the pre-trained model. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        ResNet\n",
    "\n",
    "    Examples:\n",
    "        >>> resnet18(num_classes=10, pretrained=True, **kwargs)\n",
    "    \"\"\"\n",
    "    return _resnet(\n",
    "        \"resnet18\", ResidualBlockBase, [\n",
    "            2, 2, 2, 2], num_classes, pretrained, 512, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c0afff-c56b-41a4-9f40-b9af6576affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "from mindspore.nn.loss import LossBase\n",
    "import mindspore.ops as ops\n",
    "\n",
    "class CrossEntropySmooth(LossBase):\n",
    "    \"\"\"CrossEntropy\"\"\"\n",
    "    def __init__(self, sparse=True, reduction='mean', smooth_factor=0., num_classes=1000):\n",
    "        super(CrossEntropySmooth, self).__init__()\n",
    "        self.onehot = ops.OneHot()\n",
    "        self.sparse = sparse\n",
    "        self.on_value = mindspore.Tensor(1.0 - smooth_factor, ms.float32)\n",
    "        self.off_value = ms.Tensor(1.0 * smooth_factor / (num_classes - 1), ms.float32)\n",
    "        self.ce = nn.SoftmaxCrossEntropyWithLogits(reduction=reduction)\n",
    "\n",
    "    def construct(self, logit, label):\n",
    "        if self.sparse:\n",
    "            label = self.onehot(label, ops.shape(logit)[1], self.on_value, self.off_value)\n",
    "        loss = self.ce(logit, label)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77dbd92-b8a4-4a07-b36c-c9ad092ee735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(19030:281473279522688,MainProcess):2023-01-04-11:15:32.526.452 [mindspore/train/serialization.py:648] For 'load_param_into_net', 2 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.\n",
      "[WARNING] ME(19030:281473279522688,MainProcess):2023-01-04-11:15:32.528.275 [mindspore/train/serialization.py:650] head.dense.weight is not loaded.\n",
      "[WARNING] ME(19030:281473279522688,MainProcess):2023-01-04-11:15:32.529.098 [mindspore/train/serialization.py:650] head.dense.bias is not loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete parameter from checkpoint: head.dense.weight\n",
      "Delete parameter from checkpoint: head.dense.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mindspore.train import Model\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from mindspore import nn\n",
    "LR = 1e-3  \n",
    "\n",
    "network = resnet18(54)\n",
    "param_dict = load_checkpoint(\"/data/mindcon/resnet18_224.ckpt\")\n",
    "param_filter = [x.name for x in network.head.get_parameters()]\n",
    "\n",
    "def filter_ckpt_parameter(origin_dict, param_filter):\n",
    "    \"\"\"删除origin_dict中包含param_filter参数名的元素\"\"\"\n",
    "    for key in list(origin_dict.keys()): # 获取模型的所有参数名\n",
    "        for name in param_filter: # 遍历模型中待删除的参数名\n",
    "            if name in key:\n",
    "                print(\"Delete parameter from checkpoint:\", key)\n",
    "                del origin_dict[key]\n",
    "                break\n",
    "\n",
    "# # 删除全连接层\n",
    "filter_ckpt_parameter(param_dict, param_filter)\n",
    "\n",
    "load_param_into_net(network, param_dict)\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "network_opt = nn.Momentum(params=network.trainable_params(), learning_rate=0.001, momentum=0.9)\n",
    "#network_opt = nn.Adam(params=network.trainable_params(),learning_rate=LR,beta1=0.9,beta2=0.999)\n",
    "# 定义损失函数\n",
    "network_loss = CrossEntropySmooth(sparse=True, reduction=\"mean\", smooth_factor=0.1, num_classes=54)\n",
    "#network_loss = nn.SoftmaxCrossEntropyWithLogits()\n",
    "#network_opt = nn.SGD(network.trainable_params(), learning_rate=LR)\n",
    "# 定义评价指标\n",
    "metrics = {\"Accuracy\": nn.Accuracy()}\n",
    "\n",
    "# 初始化模型\n",
    "model = Model(network, loss_fn=network_loss, optimizer=network_opt, metrics=metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662248fe-a96d-4705-a09f-c9782c418e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,stat\n",
    "from mindvision.check_param import Rel, Validator as validator\n",
    "from mindspore.train.callback import Callback\n",
    "from mindspore import save_checkpoint\n",
    "class ValAccSaveMonitor(Callback):\n",
    "    \"\"\"\n",
    "    Train loss and validation accuracy monitor, after each epoch save the\n",
    "    best checkpoint file with highest validation accuracy.\n",
    "\n",
    "    Usage:\n",
    "        >>> monitor = TrainLossAndValAccMonitor(model, dataset_val, num_epochs=10)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 dataset_val,\n",
    "                 num_epochs,\n",
    "                 interval=1,\n",
    "                 eval_start_epoch=1,\n",
    "                 save_best_ckpt=True,\n",
    "                 ckpt_directory=\"./\",\n",
    "                 best_ckpt_name=\"best.ckpt\",\n",
    "                 metric_name=\"Accuracy\",\n",
    "                 dataset_sink_mode=True):\n",
    "        super(ValAccSaveMonitor, self).__init__()\n",
    "        self.model = model\n",
    "        self.dataset_val = dataset_val\n",
    "        self.num_epochs = num_epochs\n",
    "        self.eval_start_epoch = eval_start_epoch\n",
    "        self.save_best_ckpt = save_best_ckpt\n",
    "        self.metric_name = metric_name\n",
    "        self.interval = validator.check_int(interval, 1, Rel.GE, \"interval\")\n",
    "        self.best_res = 0\n",
    "        self.dataset_sink_mode = dataset_sink_mode\n",
    "        self.ckpt_directory=ckpt_directory\n",
    "        if not os.path.isdir(ckpt_directory):\n",
    "            os.makedirs(ckpt_directory)\n",
    "        self.best_ckpt_path = os.path.join(ckpt_directory, best_ckpt_name)\n",
    "\n",
    "    def apply_eval(self):\n",
    "        \"\"\"Model evaluation, return validation accuracy.\"\"\"\n",
    "        return self.model.eval(self.dataset_val, dataset_sink_mode=self.dataset_sink_mode)[self.metric_name]\n",
    "\n",
    "    def epoch_end(self, run_context):\n",
    "        \"\"\"\n",
    "        After epoch, print train loss and val accuracy,\n",
    "        save the best ckpt file with highest validation accuracy.\n",
    "        \"\"\"\n",
    "        callback_params = run_context.original_args()\n",
    "        cur_epoch = callback_params.cur_epoch_num\n",
    "\n",
    "        if cur_epoch >= self.eval_start_epoch and (cur_epoch - self.eval_start_epoch) % self.interval == 0:\n",
    "            # Validation result\n",
    "            res = self.apply_eval()\n",
    "\n",
    "            print(\"-\" * 20)\n",
    "            print(f\"Epoch: [{cur_epoch: 3d} / {self.num_epochs: 3d}], \"\n",
    "                  f\"Train Loss: [{callback_params.net_outputs.asnumpy() :5.3f}], \"\n",
    "                  f\"{self.metric_name}: {res: 5.3f}\")\n",
    "\n",
    "            def remove_ckpt_file(file_name):\n",
    "                os.chmod(file_name, stat.S_IWRITE)\n",
    "                os.remove(file_name)\n",
    "\n",
    "            # Save the best ckpt file\n",
    "            if res >= self.best_res:\n",
    "                self.best_res = res\n",
    "                if self.save_best_ckpt:\n",
    "                    if os.path.exists(self.best_ckpt_path):\n",
    "                        remove_ckpt_file(self.best_ckpt_path)\n",
    "                    save_checkpoint(callback_params.train_network, self.best_ckpt_path)\n",
    "            if(cur_epoch%10==0):\n",
    "                save_path = os.path.join(self.ckpt_directory, \"save_{}_{}.ckpt\".format(cur_epoch,res))\n",
    "                save_checkpoint(callback_params.train_network, save_path)                \n",
    "    # pylint: disable=unused-argument\n",
    "    def end(self, run_context):\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"End of validation the best {self.metric_name} is: {self.best_res: 5.3f}, \"\n",
    "              f\"save the best ckpt file in {self.best_ckpt_path}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1cd110-226b-475a-8ef1-6d147f876eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Epoch: [  1 /  100], Train Loss: [3.658], Accuracy:  0.196\n",
      "epoch time: 54513.274 ms, per step time: 1009.505 ms\n",
      "--------------------\n",
      "Epoch: [  2 /  100], Train Loss: [3.315], Accuracy:  0.335\n",
      "epoch time: 9621.917 ms, per step time: 178.184 ms\n",
      "--------------------\n",
      "Epoch: [  3 /  100], Train Loss: [2.746], Accuracy:  0.567\n",
      "epoch time: 30008.323 ms, per step time: 555.710 ms\n",
      "--------------------\n",
      "Epoch: [  4 /  100], Train Loss: [2.577], Accuracy:  0.636\n",
      "epoch time: 26054.873 ms, per step time: 482.498 ms\n",
      "--------------------\n",
      "Epoch: [  5 /  100], Train Loss: [2.071], Accuracy:  0.719\n",
      "epoch time: 19875.729 ms, per step time: 368.069 ms\n",
      "--------------------\n",
      "Epoch: [  6 /  100], Train Loss: [2.067], Accuracy:  0.746\n",
      "epoch time: 25652.336 ms, per step time: 475.043 ms\n",
      "--------------------\n",
      "Epoch: [  7 /  100], Train Loss: [2.002], Accuracy:  0.779\n",
      "epoch time: 22056.077 ms, per step time: 408.446 ms\n",
      "--------------------\n",
      "Epoch: [  8 /  100], Train Loss: [1.721], Accuracy:  0.795\n",
      "epoch time: 27177.054 ms, per step time: 503.279 ms\n",
      "--------------------\n",
      "Epoch: [  9 /  100], Train Loss: [1.648], Accuracy:  0.826\n",
      "epoch time: 22932.271 ms, per step time: 424.672 ms\n",
      "--------------------\n",
      "Epoch: [ 10 /  100], Train Loss: [1.707], Accuracy:  0.826\n",
      "epoch time: 14939.922 ms, per step time: 276.665 ms\n",
      "--------------------\n",
      "Epoch: [ 11 /  100], Train Loss: [1.332], Accuracy:  0.848\n",
      "epoch time: 23772.371 ms, per step time: 440.229 ms\n",
      "--------------------\n",
      "Epoch: [ 12 /  100], Train Loss: [1.564], Accuracy:  0.850\n",
      "epoch time: 25509.782 ms, per step time: 472.403 ms\n",
      "--------------------\n",
      "Epoch: [ 13 /  100], Train Loss: [1.481], Accuracy:  0.857\n",
      "epoch time: 28139.002 ms, per step time: 521.093 ms\n",
      "--------------------\n",
      "Epoch: [ 14 /  100], Train Loss: [1.519], Accuracy:  0.862\n",
      "epoch time: 21404.040 ms, per step time: 396.371 ms\n",
      "--------------------\n",
      "Epoch: [ 15 /  100], Train Loss: [1.515], Accuracy:  0.873\n",
      "epoch time: 20907.563 ms, per step time: 387.177 ms\n",
      "--------------------\n",
      "Epoch: [ 16 /  100], Train Loss: [1.432], Accuracy:  0.877\n",
      "epoch time: 23209.555 ms, per step time: 429.807 ms\n",
      "--------------------\n",
      "Epoch: [ 17 /  100], Train Loss: [1.256], Accuracy:  0.877\n",
      "epoch time: 23993.164 ms, per step time: 444.318 ms\n",
      "--------------------\n",
      "Epoch: [ 18 /  100], Train Loss: [1.180], Accuracy:  0.884\n",
      "epoch time: 16599.330 ms, per step time: 307.395 ms\n",
      "--------------------\n",
      "Epoch: [ 19 /  100], Train Loss: [1.240], Accuracy:  0.897\n",
      "epoch time: 25540.194 ms, per step time: 472.967 ms\n",
      "--------------------\n",
      "Epoch: [ 20 /  100], Train Loss: [1.184], Accuracy:  0.897\n",
      "epoch time: 25333.773 ms, per step time: 469.144 ms\n",
      "--------------------\n",
      "Epoch: [ 21 /  100], Train Loss: [1.090], Accuracy:  0.897\n",
      "epoch time: 23211.737 ms, per step time: 429.847 ms\n",
      "--------------------\n",
      "Epoch: [ 22 /  100], Train Loss: [1.363], Accuracy:  0.897\n",
      "epoch time: 20887.288 ms, per step time: 386.802 ms\n",
      "--------------------\n",
      "Epoch: [ 23 /  100], Train Loss: [1.269], Accuracy:  0.897\n",
      "epoch time: 21312.358 ms, per step time: 394.673 ms\n",
      "--------------------\n",
      "Epoch: [ 24 /  100], Train Loss: [1.219], Accuracy:  0.908\n",
      "epoch time: 25558.238 ms, per step time: 473.301 ms\n",
      "--------------------\n",
      "Epoch: [ 25 /  100], Train Loss: [1.360], Accuracy:  0.911\n",
      "epoch time: 21921.067 ms, per step time: 405.946 ms\n",
      "--------------------\n",
      "Epoch: [ 26 /  100], Train Loss: [1.218], Accuracy:  0.904\n",
      "epoch time: 20825.696 ms, per step time: 385.661 ms\n",
      "--------------------\n",
      "Epoch: [ 27 /  100], Train Loss: [1.155], Accuracy:  0.913\n",
      "epoch time: 21670.390 ms, per step time: 401.304 ms\n",
      "--------------------\n",
      "Epoch: [ 28 /  100], Train Loss: [1.126], Accuracy:  0.911\n",
      "epoch time: 17439.738 ms, per step time: 322.958 ms\n",
      "--------------------\n",
      "Epoch: [ 29 /  100], Train Loss: [1.222], Accuracy:  0.906\n",
      "epoch time: 20774.773 ms, per step time: 384.718 ms\n",
      "--------------------\n",
      "Epoch: [ 30 /  100], Train Loss: [1.203], Accuracy:  0.915\n",
      "epoch time: 24904.497 ms, per step time: 461.194 ms\n",
      "--------------------\n",
      "Epoch: [ 31 /  100], Train Loss: [1.282], Accuracy:  0.920\n",
      "epoch time: 16920.939 ms, per step time: 313.351 ms\n",
      "--------------------\n",
      "Epoch: [ 32 /  100], Train Loss: [1.161], Accuracy:  0.917\n",
      "epoch time: 22378.892 ms, per step time: 414.424 ms\n",
      "--------------------\n",
      "Epoch: [ 33 /  100], Train Loss: [0.930], Accuracy:  0.915\n",
      "epoch time: 24330.012 ms, per step time: 450.556 ms\n",
      "--------------------\n",
      "Epoch: [ 34 /  100], Train Loss: [0.946], Accuracy:  0.915\n",
      "epoch time: 22587.724 ms, per step time: 418.291 ms\n",
      "--------------------\n",
      "Epoch: [ 35 /  100], Train Loss: [1.066], Accuracy:  0.924\n",
      "epoch time: 25643.513 ms, per step time: 474.880 ms\n",
      "--------------------\n",
      "Epoch: [ 36 /  100], Train Loss: [1.091], Accuracy:  0.924\n",
      "epoch time: 23914.210 ms, per step time: 442.856 ms\n",
      "--------------------\n",
      "Epoch: [ 37 /  100], Train Loss: [1.051], Accuracy:  0.929\n",
      "epoch time: 24133.098 ms, per step time: 446.909 ms\n",
      "--------------------\n",
      "Epoch: [ 38 /  100], Train Loss: [1.354], Accuracy:  0.931\n",
      "epoch time: 28683.450 ms, per step time: 531.175 ms\n",
      "--------------------\n",
      "Epoch: [ 39 /  100], Train Loss: [0.962], Accuracy:  0.931\n",
      "epoch time: 21914.866 ms, per step time: 405.831 ms\n",
      "--------------------\n",
      "Epoch: [ 40 /  100], Train Loss: [1.035], Accuracy:  0.922\n",
      "epoch time: 25196.254 ms, per step time: 466.597 ms\n",
      "--------------------\n",
      "Epoch: [ 41 /  100], Train Loss: [1.051], Accuracy:  0.931\n",
      "epoch time: 23036.243 ms, per step time: 426.597 ms\n",
      "--------------------\n",
      "Epoch: [ 42 /  100], Train Loss: [1.106], Accuracy:  0.931\n",
      "epoch time: 26865.892 ms, per step time: 497.517 ms\n",
      "--------------------\n",
      "Epoch: [ 43 /  100], Train Loss: [0.931], Accuracy:  0.926\n",
      "epoch time: 19966.693 ms, per step time: 369.754 ms\n",
      "--------------------\n",
      "Epoch: [ 44 /  100], Train Loss: [1.074], Accuracy:  0.931\n",
      "epoch time: 21728.789 ms, per step time: 402.385 ms\n",
      "--------------------\n",
      "Epoch: [ 45 /  100], Train Loss: [1.058], Accuracy:  0.924\n",
      "epoch time: 24509.776 ms, per step time: 453.885 ms\n",
      "--------------------\n",
      "Epoch: [ 46 /  100], Train Loss: [1.134], Accuracy:  0.940\n",
      "epoch time: 29165.230 ms, per step time: 540.097 ms\n",
      "--------------------\n",
      "Epoch: [ 47 /  100], Train Loss: [1.076], Accuracy:  0.944\n",
      "epoch time: 26437.380 ms, per step time: 489.581 ms\n",
      "--------------------\n",
      "Epoch: [ 48 /  100], Train Loss: [0.928], Accuracy:  0.942\n",
      "epoch time: 17592.088 ms, per step time: 325.779 ms\n",
      "--------------------\n",
      "Epoch: [ 49 /  100], Train Loss: [1.020], Accuracy:  0.933\n",
      "epoch time: 20180.604 ms, per step time: 373.715 ms\n",
      "--------------------\n",
      "Epoch: [ 50 /  100], Train Loss: [0.932], Accuracy:  0.942\n",
      "epoch time: 30343.944 ms, per step time: 561.925 ms\n",
      "--------------------\n",
      "Epoch: [ 51 /  100], Train Loss: [1.172], Accuracy:  0.935\n",
      "epoch time: 24240.700 ms, per step time: 448.902 ms\n",
      "--------------------\n",
      "Epoch: [ 52 /  100], Train Loss: [1.061], Accuracy:  0.942\n",
      "epoch time: 22576.956 ms, per step time: 418.092 ms\n",
      "--------------------\n",
      "Epoch: [ 53 /  100], Train Loss: [1.010], Accuracy:  0.935\n",
      "epoch time: 22160.607 ms, per step time: 410.382 ms\n",
      "--------------------\n",
      "Epoch: [ 54 /  100], Train Loss: [0.982], Accuracy:  0.938\n",
      "epoch time: 27074.329 ms, per step time: 501.376 ms\n",
      "--------------------\n",
      "Epoch: [ 55 /  100], Train Loss: [1.039], Accuracy:  0.940\n",
      "epoch time: 25845.998 ms, per step time: 478.630 ms\n",
      "--------------------\n",
      "Epoch: [ 56 /  100], Train Loss: [0.987], Accuracy:  0.940\n",
      "epoch time: 26096.884 ms, per step time: 483.276 ms\n",
      "--------------------\n",
      "Epoch: [ 57 /  100], Train Loss: [0.993], Accuracy:  0.942\n",
      "epoch time: 24573.756 ms, per step time: 455.070 ms\n",
      "--------------------\n",
      "Epoch: [ 58 /  100], Train Loss: [0.942], Accuracy:  0.944\n",
      "epoch time: 27046.155 ms, per step time: 500.855 ms\n",
      "--------------------\n",
      "Epoch: [ 59 /  100], Train Loss: [1.162], Accuracy:  0.944\n",
      "epoch time: 28117.716 ms, per step time: 520.698 ms\n",
      "--------------------\n",
      "Epoch: [ 60 /  100], Train Loss: [0.985], Accuracy:  0.953\n",
      "epoch time: 23152.331 ms, per step time: 428.747 ms\n",
      "--------------------\n",
      "Epoch: [ 61 /  100], Train Loss: [0.934], Accuracy:  0.951\n",
      "epoch time: 23224.404 ms, per step time: 430.082 ms\n",
      "--------------------\n",
      "Epoch: [ 62 /  100], Train Loss: [1.116], Accuracy:  0.953\n",
      "epoch time: 31802.093 ms, per step time: 588.928 ms\n",
      "--------------------\n",
      "Epoch: [ 63 /  100], Train Loss: [1.037], Accuracy:  0.953\n",
      "epoch time: 19506.474 ms, per step time: 361.231 ms\n",
      "--------------------\n",
      "Epoch: [ 64 /  100], Train Loss: [0.901], Accuracy:  0.951\n",
      "epoch time: 24485.933 ms, per step time: 453.443 ms\n",
      "--------------------\n",
      "Epoch: [ 65 /  100], Train Loss: [0.922], Accuracy:  0.960\n",
      "epoch time: 23869.246 ms, per step time: 442.023 ms\n",
      "--------------------\n",
      "Epoch: [ 66 /  100], Train Loss: [1.151], Accuracy:  0.955\n",
      "epoch time: 17355.469 ms, per step time: 321.398 ms\n",
      "--------------------\n",
      "Epoch: [ 67 /  100], Train Loss: [1.027], Accuracy:  0.951\n",
      "epoch time: 22812.366 ms, per step time: 422.451 ms\n",
      "--------------------\n",
      "Epoch: [ 68 /  100], Train Loss: [1.053], Accuracy:  0.955\n",
      "epoch time: 24091.970 ms, per step time: 446.148 ms\n",
      "--------------------\n",
      "Epoch: [ 69 /  100], Train Loss: [1.028], Accuracy:  0.951\n",
      "epoch time: 23418.944 ms, per step time: 433.684 ms\n",
      "--------------------\n",
      "Epoch: [ 70 /  100], Train Loss: [1.041], Accuracy:  0.951\n",
      "epoch time: 22715.650 ms, per step time: 420.660 ms\n",
      "--------------------\n",
      "Epoch: [ 71 /  100], Train Loss: [1.035], Accuracy:  0.953\n",
      "epoch time: 22186.665 ms, per step time: 410.864 ms\n",
      "--------------------\n",
      "Epoch: [ 72 /  100], Train Loss: [1.014], Accuracy:  0.949\n",
      "epoch time: 29958.420 ms, per step time: 554.786 ms\n",
      "--------------------\n",
      "Epoch: [ 73 /  100], Train Loss: [1.006], Accuracy:  0.949\n",
      "epoch time: 26472.260 ms, per step time: 490.227 ms\n",
      "--------------------\n",
      "Epoch: [ 74 /  100], Train Loss: [0.934], Accuracy:  0.953\n",
      "epoch time: 23359.029 ms, per step time: 432.575 ms\n",
      "--------------------\n",
      "Epoch: [ 75 /  100], Train Loss: [0.893], Accuracy:  0.958\n",
      "epoch time: 23056.864 ms, per step time: 426.979 ms\n",
      "--------------------\n",
      "Epoch: [ 76 /  100], Train Loss: [0.902], Accuracy:  0.955\n",
      "epoch time: 21468.471 ms, per step time: 397.564 ms\n",
      "--------------------\n",
      "Epoch: [ 77 /  100], Train Loss: [1.098], Accuracy:  0.955\n",
      "epoch time: 28337.587 ms, per step time: 524.770 ms\n",
      "--------------------\n",
      "Epoch: [ 78 /  100], Train Loss: [0.935], Accuracy:  0.955\n",
      "epoch time: 24241.694 ms, per step time: 448.920 ms\n",
      "--------------------\n",
      "Epoch: [ 79 /  100], Train Loss: [0.906], Accuracy:  0.949\n",
      "epoch time: 23084.668 ms, per step time: 427.494 ms\n",
      "--------------------\n",
      "Epoch: [ 80 /  100], Train Loss: [0.894], Accuracy:  0.951\n",
      "epoch time: 24500.224 ms, per step time: 453.708 ms\n",
      "--------------------\n",
      "Epoch: [ 81 /  100], Train Loss: [1.047], Accuracy:  0.958\n",
      "epoch time: 21772.163 ms, per step time: 403.188 ms\n",
      "--------------------\n",
      "Epoch: [ 82 /  100], Train Loss: [0.920], Accuracy:  0.958\n",
      "epoch time: 22628.299 ms, per step time: 419.043 ms\n",
      "--------------------\n",
      "Epoch: [ 83 /  100], Train Loss: [0.941], Accuracy:  0.960\n",
      "epoch time: 24963.905 ms, per step time: 462.295 ms\n",
      "--------------------\n",
      "Epoch: [ 84 /  100], Train Loss: [0.878], Accuracy:  0.953\n",
      "epoch time: 30053.932 ms, per step time: 556.554 ms\n",
      "--------------------\n",
      "Epoch: [ 85 /  100], Train Loss: [1.007], Accuracy:  0.951\n",
      "epoch time: 28361.397 ms, per step time: 525.211 ms\n",
      "--------------------\n",
      "Epoch: [ 86 /  100], Train Loss: [0.914], Accuracy:  0.960\n",
      "epoch time: 24987.751 ms, per step time: 462.736 ms\n",
      "--------------------\n",
      "Epoch: [ 87 /  100], Train Loss: [0.943], Accuracy:  0.955\n",
      "epoch time: 30531.675 ms, per step time: 565.401 ms\n",
      "--------------------\n",
      "Epoch: [ 88 /  100], Train Loss: [0.893], Accuracy:  0.949\n",
      "epoch time: 39211.622 ms, per step time: 726.141 ms\n",
      "--------------------\n",
      "Epoch: [ 89 /  100], Train Loss: [0.875], Accuracy:  0.958\n",
      "epoch time: 28023.646 ms, per step time: 518.956 ms\n",
      "--------------------\n",
      "Epoch: [ 90 /  100], Train Loss: [0.921], Accuracy:  0.960\n",
      "epoch time: 26428.578 ms, per step time: 489.418 ms\n",
      "--------------------\n",
      "Epoch: [ 91 /  100], Train Loss: [0.944], Accuracy:  0.955\n",
      "epoch time: 23850.289 ms, per step time: 441.672 ms\n",
      "--------------------\n",
      "Epoch: [ 92 /  100], Train Loss: [0.924], Accuracy:  0.958\n",
      "epoch time: 21890.089 ms, per step time: 405.372 ms\n",
      "--------------------\n",
      "Epoch: [ 93 /  100], Train Loss: [0.926], Accuracy:  0.953\n",
      "epoch time: 27594.243 ms, per step time: 511.004 ms\n",
      "--------------------\n",
      "Epoch: [ 94 /  100], Train Loss: [0.942], Accuracy:  0.944\n",
      "epoch time: 26643.540 ms, per step time: 493.399 ms\n",
      "--------------------\n",
      "Epoch: [ 95 /  100], Train Loss: [0.839], Accuracy:  0.949\n",
      "epoch time: 21043.648 ms, per step time: 389.697 ms\n",
      "--------------------\n",
      "Epoch: [ 96 /  100], Train Loss: [0.965], Accuracy:  0.949\n",
      "epoch time: 24283.974 ms, per step time: 449.703 ms\n",
      "--------------------\n",
      "Epoch: [ 97 /  100], Train Loss: [1.034], Accuracy:  0.953\n",
      "epoch time: 24287.315 ms, per step time: 449.765 ms\n",
      "--------------------\n",
      "Epoch: [ 98 /  100], Train Loss: [0.927], Accuracy:  0.949\n",
      "epoch time: 28511.460 ms, per step time: 527.990 ms\n",
      "--------------------\n",
      "Epoch: [ 99 /  100], Train Loss: [0.924], Accuracy:  0.949\n",
      "epoch time: 21976.330 ms, per step time: 406.969 ms\n",
      "--------------------\n",
      "Epoch: [ 100 /  100], Train Loss: [0.906], Accuracy:  0.953\n",
      "epoch time: 25042.553 ms, per step time: 463.751 ms\n",
      "================================================================================\n",
      "End of validation the best Accuracy is:  0.960, save the best ckpt file in /data/mindcon/result/resnet_best_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from mindspore.train.callback import TimeMonitor\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# 模型训练与验证，训练完成后保存验证精度最高的ckpt文件（best.ckpt）到当前目录下\n",
    "model.train(num_epochs, \n",
    "            dataset_train,\n",
    "            callbacks=[ValAccSaveMonitor(model, dataset_val, num_epochs,ckpt_directory=\"/data/mindcon/result/\",\n",
    "                 best_ckpt_name=\"resnet_best_2.ckpt\",), TimeMonitor()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247843d4-47bd-4558-b39e-76e21cd1aa03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
